{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# This notebook is investigating TB and surface temperature data for the Hunza met station locations\n",
    "\n",
    "## Load in all the modules needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "%pylab notebook\n",
    "import cartopy.crs as ccrs\n",
    "import cartopy.io.shapereader as shpreader\n",
    "import shapely.geometry as sgeom\n",
    "import matplotlib.pyplot as plt\n",
    "from netCDF4 import Dataset, num2date\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import rasterio\n",
    "from cetbtools.ease2conv import Ease2Transform\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/projects/brodzik/ipynb_melt_onset/scripts\n",
      "CETB_algorithms.py  CETB_analysis.py~       \u001b[0m\u001b[01;34m__pycache__\u001b[0m/\r\n",
      "CETB_analysis.py    CETB_read_functions.py\r\n"
     ]
    }
   ],
   "source": [
    "# navigate to where scripts are saved\n",
    "%cd /projects/brodzik/ipynb_melt_onset/scripts/\n",
    "%ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# load the custom functions\n",
    "from CETB_read_functions import read_Tb\n",
    "from CETB_read_functions import calc_DAV\n",
    "from CETB_analysis import MOD_array_year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Set pixel lookups by met station\n",
    "# ref: /Users/brodzik/Desktop/GIS_data/Pakistan/Hunza/wapda_met_stations_CETBlocs.v4.xlsx\n",
    "Khunjerab = {\"name\": \"Khunjerab\",\n",
    "             \"lat\": 36.8411,\n",
    "             \"lon\": 75.4192,\n",
    "             \"elevation\": 4440,\n",
    "             \"row3km\": 220,\n",
    "             \"col3km\": 41,\n",
    "             \"row25km\": 27,\n",
    "             \"col25km\": 5\n",
    "           }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Set pixel lookups by met station\n",
    "# ref: /Users/brodzik/Desktop/GIS_data/Pakistan/Hunza/wapda_met_stations_CETBlocs.v4.xlsx\n",
    "Ziarat = {\"name\": \"Ziarat\",\n",
    "             \"lat\": 36.798,\n",
    "             \"lon\": 74.482,\n",
    "             \"elevation\": 3020,\n",
    "             \"row3km\": 249,\n",
    "             \"col3km\": 34,\n",
    "             \"row25km\": 31,\n",
    "             \"col25km\": 4\n",
    "           }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Set pixel lookups by met station\n",
    "# ref: /Users/brodzik/Desktop/GIS_data/Pakistan/Hunza/wapda_met_stations_CETBlocs.v4.xlsx\n",
    "Naltar = {\"name\": \"Naltar\",\n",
    "          \"lat\": 36.1667,\n",
    "          \"lon\": 74.1833,\n",
    "          \"elevation\": 2898,\n",
    "          \"row3km\": 264,\n",
    "          \"col3km\": 51,\n",
    "          \"row6km\": 132,\n",
    "          \"col6km\": 26,\n",
    "          \"row25km\": 33,\n",
    "          \"col25km\": 6\n",
    "           }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read TB data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Specify region, satellite, sensor, channel, and image reconstruction algorithm of interest in file name\n",
    "# this notebook will read in 2 CETB datasets so that channels/algorithms/sensors can be compared\n",
    "region='UIB'  #make this the same syntax as cubefilenames and sub-directory\n",
    "platform='AQUA'   #'AQUA' for AMSRE, 'F13','F14','F15'... for SSMI\n",
    "sensor='AMSRE'  #'AMSRE', 'SSMI', etc.\n",
    "channel='36V'  #'36V','36H', '18V','18H', etc. '19V','19H' and '37V','37H' for SSMI)\n",
    "version='v1.3'\n",
    "proj='N'\n",
    "\n",
    "if sensor=='SSMI':\n",
    "    provider='CSU' \n",
    "elif sensor=='AMSRE':\n",
    "    provider='RSS'\n",
    "\n",
    "cubeDir = '/work/PMESDR/CETB_v1.3/%s_%s/%s/cubes_%s/' % (platform, sensor, proj, region)    \n",
    "\n",
    "# prefix filepath\n",
    "prefix_GRD = 'CETB.cubefile.%s.%s_%s-%s-GRD-%s-%s' % (region, platform, sensor, channel, provider, version)\n",
    "prefix_SIR = 'CETB.cubefile.%s.%s_%s-%s-SIR-%s-%s' % (region, platform, sensor, channel, provider, version)\n",
    "\n",
    "# years for each sensor\n",
    "# F13, May 95 - Nov 09\n",
    "if platform=='F13':\n",
    "    # F13, May 95 - Nov 09\n",
    "    Years = [2002,2003,2004,2005,2006,2007,2008,2009]\n",
    "elif platform=='F14':\n",
    "    # F14, May 97 - Aug 08\n",
    "    Years=[2002,2003,2004,2005,2006,2007,2008]\n",
    "elif platform=='F15':\n",
    "    # F15, Feb 00 - Jun 17\n",
    "    Years=[2002,2003,2004,2005,2006,2007,2008,2009,2010,2011]\n",
    "elif platform=='F17':\n",
    "    # F17, Mar 08 - Jun 17\n",
    "    Years=[2009,2010,2011,2012,2013,2014,2015,2016,2017]\n",
    "elif platform=='AQUA':\n",
    "    # AQUA AMSR-E: Jun 02 - Oct 11\n",
    "    Years=[2003,2004,2005,2006,2007,2008,2009,2010,2011]\n",
    "    #Years=[2003,2004]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No subset specified, fetching complete cube...\n",
      "Next filename=/work/PMESDR/CETB_v1.3/AQUA_AMSRE/N/cubes_UIB/CETB.cubefile.UIB.AQUA_AMSRE-36V-SIR-RSS-v1.3.2003.TB.nc...\n",
      "Next filename=/work/PMESDR/CETB_v1.3/AQUA_AMSRE/N/cubes_UIB/CETB.cubefile.UIB.AQUA_AMSRE-36V-SIR-RSS-v1.3.2004.TB.nc...\n",
      "Next filename=/work/PMESDR/CETB_v1.3/AQUA_AMSRE/N/cubes_UIB/CETB.cubefile.UIB.AQUA_AMSRE-36V-SIR-RSS-v1.3.2005.TB.nc...\n",
      "Next filename=/work/PMESDR/CETB_v1.3/AQUA_AMSRE/N/cubes_UIB/CETB.cubefile.UIB.AQUA_AMSRE-36V-SIR-RSS-v1.3.2006.TB.nc...\n",
      "Next filename=/work/PMESDR/CETB_v1.3/AQUA_AMSRE/N/cubes_UIB/CETB.cubefile.UIB.AQUA_AMSRE-36V-SIR-RSS-v1.3.2007.TB.nc...\n",
      "Next filename=/work/PMESDR/CETB_v1.3/AQUA_AMSRE/N/cubes_UIB/CETB.cubefile.UIB.AQUA_AMSRE-36V-SIR-RSS-v1.3.2008.TB.nc...\n",
      "Next filename=/work/PMESDR/CETB_v1.3/AQUA_AMSRE/N/cubes_UIB/CETB.cubefile.UIB.AQUA_AMSRE-36V-SIR-RSS-v1.3.2009.TB.nc...\n",
      "Next filename=/work/PMESDR/CETB_v1.3/AQUA_AMSRE/N/cubes_UIB/CETB.cubefile.UIB.AQUA_AMSRE-36V-SIR-RSS-v1.3.2010.TB.nc...\n",
      "Next filename=/work/PMESDR/CETB_v1.3/AQUA_AMSRE/N/cubes_UIB/CETB.cubefile.UIB.AQUA_AMSRE-36V-SIR-RSS-v1.3.2011.TB.nc...\n",
      "No subset specified, fetching complete cube...\n",
      "Next filename=/work/PMESDR/CETB_v1.3/AQUA_AMSRE/N/cubes_UIB/CETB.cubefile.UIB.AQUA_AMSRE-36V-GRD-RSS-v1.3.2003.TB.nc...\n",
      "Next filename=/work/PMESDR/CETB_v1.3/AQUA_AMSRE/N/cubes_UIB/CETB.cubefile.UIB.AQUA_AMSRE-36V-GRD-RSS-v1.3.2004.TB.nc...\n",
      "Next filename=/work/PMESDR/CETB_v1.3/AQUA_AMSRE/N/cubes_UIB/CETB.cubefile.UIB.AQUA_AMSRE-36V-GRD-RSS-v1.3.2005.TB.nc...\n",
      "Next filename=/work/PMESDR/CETB_v1.3/AQUA_AMSRE/N/cubes_UIB/CETB.cubefile.UIB.AQUA_AMSRE-36V-GRD-RSS-v1.3.2006.TB.nc...\n",
      "Next filename=/work/PMESDR/CETB_v1.3/AQUA_AMSRE/N/cubes_UIB/CETB.cubefile.UIB.AQUA_AMSRE-36V-GRD-RSS-v1.3.2007.TB.nc...\n",
      "Next filename=/work/PMESDR/CETB_v1.3/AQUA_AMSRE/N/cubes_UIB/CETB.cubefile.UIB.AQUA_AMSRE-36V-GRD-RSS-v1.3.2008.TB.nc...\n",
      "Next filename=/work/PMESDR/CETB_v1.3/AQUA_AMSRE/N/cubes_UIB/CETB.cubefile.UIB.AQUA_AMSRE-36V-GRD-RSS-v1.3.2009.TB.nc...\n",
      "Next filename=/work/PMESDR/CETB_v1.3/AQUA_AMSRE/N/cubes_UIB/CETB.cubefile.UIB.AQUA_AMSRE-36V-GRD-RSS-v1.3.2010.TB.nc...\n",
      "Next filename=/work/PMESDR/CETB_v1.3/AQUA_AMSRE/N/cubes_UIB/CETB.cubefile.UIB.AQUA_AMSRE-36V-GRD-RSS-v1.3.2011.TB.nc...\n"
     ]
    }
   ],
   "source": [
    "# load in SIR TB data for the whole cube\n",
    "data_SIR=read_Tb(cubeDir, prefix_SIR, Years)\n",
    "CETB_SIR=data_SIR['TB']   # 3-D Tb time-series array of TB\n",
    "\n",
    "# load GRD Tb data\n",
    "data_GRD=read_Tb(cubeDir, prefix_GRD, Years)\n",
    "CETB_GRD=data_GRD['TB']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# calculate DAV for the Tb data that was imported\n",
    "DAV_SIR=calc_DAV(CETB_SIR)\n",
    "DAV_GRD=calc_DAV(CETB_GRD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "if sensor == 'AMSRE':\n",
    "    window=10   # window for MOD algorithm, '10' would be 5 days (2 measurements per day)\n",
    "    DAV_threshold=40\n",
    "    Tb_threshold=252\n",
    "elif sensor == 'SSMI':\n",
    "    window=14   # use 7 days for SSMI?\n",
    "    DAV_threshold=18\n",
    "    Tb_threshold=240\n",
    "else:\n",
    "    window=10   # not sure about SSMIS\n",
    "    DAV_threshold=25\n",
    "    Tb_threshold=252\n",
    "count=3    # number of Tb/DAV exceedances to trigger MOD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def calculate_station_MOD_for_year(station, data_SIR, DAV_SIR, data_GRD, DAV_GRD,\n",
    "                                   year, window, count, DAV_threshold, Tb_threshold):\n",
    "    \n",
    "    # calculate the MOD dates for SIR and GRD\n",
    "\n",
    "    # Define subsets for the one pixel that contains the current station\n",
    "    # rows_cols subsets should be [row, row+1, col, col+1]\n",
    "    rows_cols_env = [station['row3km'], station['row3km']+1,\n",
    "                     station['col3km'], station['col3km']+1]\n",
    "    rows_cols_GRD = [station['row25km'], station['row25km']+1,\n",
    "                     station['col25km'], station['col25km']+1]\n",
    "    print(\"rows_cols:\")\n",
    "    print(rows_cols_env)\n",
    "    print(rows_cols_GRD)\n",
    "            \n",
    "    # sir MOD array - MOD will be in day of year (DOY)\n",
    "    MOD_DOY_array_year=MOD_array_year(cubeDir, prefix_SIR, \n",
    "                                      data_SIR['TB'][:,\n",
    "                                               rows_cols_env[0]:rows_cols_env[1],\n",
    "                                               rows_cols_env[2]:rows_cols_env[3]],\n",
    "                                      DAV_SIR[:,\n",
    "                                              rows_cols_env[0]:rows_cols_env[1],\n",
    "                                              rows_cols_env[2]:rows_cols_env[3]], \n",
    "                                      rows_cols_env, data_SIR['cal_date'], \n",
    "                                      year, window, count, DAV_threshold, Tb_threshold)\n",
    "\n",
    "    MOD_DOY_array_GRD_year=MOD_array_year(cubeDir, prefix_GRD,\n",
    "                                          data_GRD['TB'][:,\n",
    "                                                         rows_cols_GRD[0]:rows_cols_GRD[1],\n",
    "                                                         rows_cols_GRD[2]:rows_cols_GRD[3]],\n",
    "                                          DAV_GRD[:,\n",
    "                                                  rows_cols_GRD[0]:rows_cols_GRD[1],\n",
    "                                                  rows_cols_GRD[2]:rows_cols_GRD[3]], \n",
    "                                          rows_cols_GRD, data_GRD['cal_date'], \n",
    "                                          year, window, count, DAV_threshold, Tb_threshold)\n",
    "    return {\"SIR_MOD\": MOD_DOY_array_year,\n",
    "            \"GRD_MOD\": MOD_DOY_array_GRD_year}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([2003, 2004, 2005, 2006, 2007, 2008, 2009, 2010, 2011], 10, 3, 40, 252)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Years, window, count, DAV_threshold, Tb_threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rows_cols:\n",
      "[220, 221, 41, 42]\n",
      "[27, 28, 5, 6]\n",
      "[143.0]\n",
      "[142.0]\n",
      "rows_cols:\n",
      "[220, 221, 41, 42]\n",
      "[27, 28, 5, 6]\n",
      "[136.0]\n",
      "[134.0]\n",
      "rows_cols:\n",
      "[220, 221, 41, 42]\n",
      "[27, 28, 5, 6]\n",
      "[113.0]\n",
      "[113.0]\n",
      "rows_cols:\n",
      "[220, 221, 41, 42]\n",
      "[27, 28, 5, 6]\n",
      "[117.0]\n",
      "[114.0]\n",
      "rows_cols:\n",
      "[220, 221, 41, 42]\n",
      "[27, 28, 5, 6]\n",
      "[104.0]\n",
      "[104.0]\n",
      "rows_cols:\n",
      "[220, 221, 41, 42]\n",
      "[27, 28, 5, 6]\n",
      "[124.0]\n",
      "[123.0]\n",
      "rows_cols:\n",
      "[220, 221, 41, 42]\n",
      "[27, 28, 5, 6]\n",
      "[149.0]\n",
      "[136.0]\n",
      "rows_cols:\n",
      "[220, 221, 41, 42]\n",
      "[27, 28, 5, 6]\n",
      "[118.0]\n",
      "[118.0]\n",
      "rows_cols:\n",
      "[220, 221, 41, 42]\n",
      "[27, 28, 5, 6]\n",
      "[116.0]\n",
      "[116.0]\n",
      "SIR_MOD\n",
      "[Timestamp('2003-05-23 00:00:00'), Timestamp('2004-05-15 00:00:00'), Timestamp('2005-04-23 00:00:00'), Timestamp('2006-04-27 00:00:00'), Timestamp('2007-04-14 00:00:00'), Timestamp('2008-05-03 00:00:00'), Timestamp('2009-05-29 00:00:00'), Timestamp('2010-04-28 00:00:00'), Timestamp('2011-04-26 00:00:00')]\n",
      "GRD_MOD\n",
      "[Timestamp('2003-05-22 00:00:00'), Timestamp('2004-05-13 00:00:00'), Timestamp('2005-04-23 00:00:00'), Timestamp('2006-04-24 00:00:00'), Timestamp('2007-04-14 00:00:00'), Timestamp('2008-05-02 00:00:00'), Timestamp('2009-05-16 00:00:00'), Timestamp('2010-04-28 00:00:00'), Timestamp('2011-04-26 00:00:00')]\n"
     ]
    }
   ],
   "source": [
    "station = Khunjerab\n",
    "#station = Ziarat\n",
    "station_SIR_MOD = []\n",
    "station_GRD_MOD = []\n",
    "for year in Years:\n",
    "    out = calculate_station_MOD_for_year(station, data_SIR, DAV_SIR, data_GRD, DAV_GRD,\n",
    "                                         year, window, count, DAV_threshold, Tb_threshold)\n",
    "    print(out[\"SIR_MOD\"])\n",
    "    if math.isnan(out[\"SIR_MOD\"]):\n",
    "        print(\"no MOD detected\")\n",
    "    else:\n",
    "        station_SIR_MOD.append(pd.to_datetime(year*1000 + int(out[\"SIR_MOD\"][0]), format='%Y%j'))\n",
    "        \n",
    "    print(out[\"GRD_MOD\"])\n",
    "    if math.isnan(out[\"GRD_MOD\"]):\n",
    "        print(\"no MOD detected\")\n",
    "    else:\n",
    "        station_GRD_MOD.append(pd.to_datetime(year*1000 + int(out[\"GRD_MOD\"][0]), format='%Y%j'))\n",
    "\n",
    "print(\"SIR_MOD\")\n",
    "print(station_SIR_MOD)\n",
    "print(\"GRD_MOD\")\n",
    "print(station_GRD_MOD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def read_station_year(station_name, year):\n",
    "    \n",
    "    stationFile = \"/work/charis/ti_model/surface_met_data/WAPDA/v1/%s/%s_%d.qc1.txt\" % (\n",
    "        station_name.lower(), station_name.lower(), year)\n",
    "    print(\"Reading station data from %s\" % stationFile)\n",
    "    station_df = pd.read_csv(stationFile, sep='\\s+', skiprows=[0])\n",
    "\n",
    "    station_df.rename(columns={'#YYYY': 'year',\n",
    "                               'MM': 'month', \n",
    "                               'DD': 'day'}, inplace=True)\n",
    "\n",
    "    station_df['yyyy-mm-dd'] = pd.to_datetime(station_df[['year', 'month', 'day']])\n",
    "    station_df.set_index('yyyy-mm-dd', inplace=True)\n",
    "    return station_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "\n",
    "# FIXME: no station data for 2011, handle the case where there is no station data for a given year\n",
    "# Khunjerab, Ziarat have no station data for 2011\n",
    "frames = [ read_station_year(station['name'], year) for year in Years[:-1] ]\n",
    "station_df = pd.concat(frames)\n",
    "station_df.replace(-9999.0, np.nan, inplace=True)\n",
    "station_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read discharge data for Hunza at Dainyor Bridge\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def read_discharge_for_year(year):\n",
    "    \n",
    "    # Now read the individual years, they are a slightly different format\n",
    "    dischargeFile = '/work/charis/ti_model/streamflow/Pakistan/Hunza/hunza_at_dainyor_bridge_daily_timeseries_%d.txt' % year\n",
    "    df = pd.read_csv(dischargeFile, header=None, sep='\\s+',\n",
    "                     names=['year', 'month', 'day', 'doy', 'Q', 'dummy'])\n",
    "\n",
    "    df['Date'] = pd.to_datetime(df.year*10000 + df.month*100 + df.day, format='%Y%m%d')\n",
    "    df.set_index('Date', drop=True, inplace=True)\n",
    "    df.drop(['year','month','day', 'doy', 'dummy'], axis=1, inplace=True)\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dischargeFile = '/work/charis/ti_model/streamflow/Pakistan/Hunza/hunza_at_danyor_bridge_daily_timeseries_1966to2000.txt'\n",
    "hunza = pd.read_csv(dischargeFile, header=None, sep='\\s+',\n",
    "                    names=['year', 'month', 'day', 'doy', 'Q'])\n",
    "\n",
    "hunza['Date'] = pd.to_datetime(hunza.year*10000 + hunza.month*100 + hunza.day,format='%Y%m%d')\n",
    "hunza.set_index('Date', drop=True, inplace=True)\n",
    "hunza.drop(['year','month','day', 'doy'], axis=1, inplace=True)\n",
    "\n",
    "sub_index = hunza.index[hunza.index < pd.to_datetime('2001-01-01')]\n",
    "hunza = hunza.loc[sub_index]\n",
    "\n",
    "# Fill in the data for later years\n",
    "# Sometimes this was missing in the original file, but sometimes it was there,\n",
    "# but we have higher confidence in the individual year files per Andy's notes\n",
    "frames = [ read_discharge_for_year(year) for year in [2001, 2002, 2003, 2004, 2008, 2009, 2010] ]\n",
    "discharge_df = pd.concat(frames)\n",
    "hunza = pd.concat([hunza, discharge_df])\n",
    "\n",
    "hunza.replace(-9999.99, np.nan, inplace=True)\n",
    "\n",
    "# Reindex, with nans for any missing dates so they don't get plotted with connecting lines\n",
    "idx = pd.date_range(hunza.index[0], hunza.index[-1])\n",
    "hunza = hunza.reindex(idx, fill_value=np.nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# subset for the years we are plotting\n",
    "sub_index = hunza.index[hunza.index >= pd.to_datetime('%s-01-01' % Years[0])]\n",
    "hunza = hunza.loc[sub_index]\n",
    "sub_index = hunza.index[hunza.index <= pd.to_datetime('%s-12-31' % Years[-1])]\n",
    "hunza = hunza.loc[sub_index]\n",
    "#hunza"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1,1)\n",
    "hunza['Q'].plot(ax=ax, label='$Q$', color='dimgray')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## For each station, fetch the data there and plot it as tseries and histogram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "do_MOD_lines = True\n",
    "stations = [Khunjerab, Ziarat, Naltar]\n",
    "for station in stations[1:2]:\n",
    "    print(station)\n",
    "    station_GRD = data_GRD['TB'][:, \n",
    "                                 station['row25km']:station['row25km']+1,\n",
    "                                 station['col25km']:station['col25km']+1].flatten()\n",
    "    station_SIR = data_SIR['TB'][:, \n",
    "                                 station['row3km']:station['row3km']+1,\n",
    "                                 station['col3km']:station['col3km']+1].flatten()\n",
    "    \n",
    "    station_GRD_DAV = DAV_GRD[:, \n",
    "                              station['row25km']:station['row25km']+1,\n",
    "                              station['col25km']:station['col25km']+1].flatten()\n",
    "    station_SIR_DAV = DAV_SIR[:, \n",
    "                              station['row3km']:station['row3km']+1,\n",
    "                              station['col3km']:station['col3km']+1].flatten()\n",
    "\n",
    "    grd_col_name = \"%s_GRD\" % channel\n",
    "    sir_col_name = \"%s_SIR\" % channel\n",
    "    grd_dav_col_name = \"%s_GRD DAV\" % channel\n",
    "    sir_dav_col_name = \"%s_SIR DAV\" % channel\n",
    "    df = pd.DataFrame(data=station_GRD, index=data_GRD['cal_date'], columns=[grd_col_name])\n",
    "    df[sir_col_name] = station_SIR\n",
    "    df[grd_dav_col_name] = station_GRD_DAV\n",
    "    df[sir_dav_col_name] = station_SIR_DAV\n",
    "    #print(df)\n",
    "\n",
    "    # Plot Tb data\n",
    "    fig, axes = plt.subplots(6,1, sharex=True, figsize=(12, 16))\n",
    "    df[sir_col_name].plot(ax=axes[0], label=sir_col_name, color='skyblue')\n",
    "    df[sir_dav_col_name].plot(ax=axes[1], label=sir_dav_col_name, color='skyblue')\n",
    "    df[grd_col_name].plot(ax=axes[2], label=grd_col_name, color='dodgerblue')\n",
    "    df[grd_dav_col_name].plot(ax=axes[3], label=grd_dav_col_name, color='dodgerblue')\n",
    "    station_df['T_max(C)'].plot(ax=axes[4], label='$T_{max} (^oC)$', color='dimgray')\n",
    "    station_df['T_min(C)'].plot(ax=axes[4], label='$T_{min} (^oC)$', color='darkgray')\n",
    "    hunza['Q'].plot(ax=axes[5], label='Dainyor Bridge Discharge', color='black')\n",
    "    \n",
    "    # Set y axis labels\n",
    "    axes[0].set_ylabel('$T_B$ ($K$)')\n",
    "    axes[1].set_ylabel('DAV ($K$)')\n",
    "    axes[2].set_ylabel('$T_B (K)$')\n",
    "    axes[3].set_ylabel('DAV ($K$)')\n",
    "    axes[4].set_ylabel('Temperature ($^oC$)')\n",
    "    axes[5].set_ylabel('Q ($m^3 s^{-1}$)')\n",
    "    \n",
    "    axes[0].set_title(\"%s %s at %s\" % (platform, sensor, station['name']))\n",
    "    #axes[1].set_title(\"%s %s %s at %s\" % (platform, sensor, grd_col_name, station['name']))\n",
    "    \n",
    "    if do_MOD_lines:\n",
    "        # Add lines for SIR MODs to SIR TB and DAV\n",
    "        for ax in [axes[0], axes[1]]:\n",
    "            for i, mod in enumerate(station_SIR_MOD):\n",
    "                if i == 0:\n",
    "                    ax.axvline(x=mod, color='orangered',\n",
    "                               linestyle=\"-\",\n",
    "                               label=\"SIR Melt Onset\")\n",
    "                else:\n",
    "                    ax.axvline(x=mod, color='orangered',\n",
    "                               linestyle=\"-\")\n",
    "        for ax in [axes[0]]:\n",
    "            for i, mod in enumerate(station_SIR_MOD):\n",
    "                if i == 0:\n",
    "                    label = \" Melt Onset\"\n",
    "                else:\n",
    "                    label = \"\"\n",
    "                ax.annotate(label,\n",
    "                            xy=(mod, 200.), \n",
    "                            xytext=(mod, 162.),\n",
    "                            arrowprops=dict(facecolor='orangered', \n",
    "                                            headwidth=6,\n",
    "                                            width=3,\n",
    "                                            shrink=0.05),\n",
    "                            fontsize=14,\n",
    "                            color='orangered',\n",
    "                            horizontalalignment='center')\n",
    "        for ax in [axes[1]]:\n",
    "            for i, mod in enumerate(station_SIR_MOD):\n",
    "                if i == 0:\n",
    "                    label = \"\"\n",
    "                    xytext = (mod, 100.)\n",
    "                else:\n",
    "                    label = \"\"\n",
    "                    xytext = (mod, 110.)\n",
    "                ax.annotate(label,\n",
    "                            xy=(mod, 70.), \n",
    "                            xytext=xytext,\n",
    "                            arrowprops=dict(facecolor='orangered', \n",
    "                                            headwidth=6,\n",
    "                                            width=3,\n",
    "                                            shrink=0.05),\n",
    "                            fontsize=12,\n",
    "                            color='orangered',\n",
    "                            horizontalalignment='center')\n",
    "                \n",
    "        # Add lines for GRD MODs to GRD Tb and DAV\n",
    "        for ax in [axes[2], axes[3]]:\n",
    "            for i, mod in enumerate(station_GRD_MOD):\n",
    "                if i == 0:\n",
    "                    ax.axvline(x=mod, color='orangered',\n",
    "                               linestyle=\"-\",\n",
    "                               label=\"GRD Melt Onset\")\n",
    "                else:\n",
    "                    ax.axvline(x=mod, color='orangered',\n",
    "                               linestyle=\"-\")\n",
    "        for ax in [axes[2]]:\n",
    "            for i, mod in enumerate(station_GRD_MOD):\n",
    "                if i == 0:\n",
    "                    label = \" Melt Onset\"\n",
    "                else:\n",
    "                    label = \"\"\n",
    "                ax.annotate(label,\n",
    "                            xy=(mod, 200.), \n",
    "                            xytext=(mod, 169.),\n",
    "                            arrowprops=dict(facecolor='orangered', \n",
    "                                            headwidth=6,\n",
    "                                            width=3,\n",
    "                                            shrink=0.05),\n",
    "                            fontsize=14,\n",
    "                            color='orangered',\n",
    "                            horizontalalignment='center')\n",
    "\n",
    "        for ax in [axes[3]]:\n",
    "            for i, mod in enumerate(station_GRD_MOD):\n",
    "                if i == 0:\n",
    "                    label = \"\"\n",
    "                    xytext = (mod, 85.)\n",
    "                else:\n",
    "                    label = \"\"\n",
    "                    xytext = (mod, 95.)\n",
    "                ax.annotate(label,\n",
    "                            xy=(mod, 70.), \n",
    "                            xytext=xytext,\n",
    "                            arrowprops=dict(facecolor='orangered', \n",
    "                                            headwidth=6,\n",
    "                                            width=3,\n",
    "                                            shrink=0.05),\n",
    "                            fontsize=12,\n",
    "                            color='orangered',\n",
    "                            horizontalalignment='center')\n",
    "\n",
    "        # Add lines for SIR MODs to station temperatures\n",
    "        for ax in [axes[4]]:\n",
    "            for i, mod in enumerate(station_SIR_MOD):\n",
    "                if i == 0:\n",
    "                    ax.axvline(x=mod, color='orangered',\n",
    "                               linestyle=\"-\",\n",
    "                               label=\"SIR Melt Onset\")\n",
    "                else:\n",
    "                    ax.axvline(x=mod, color='orangered',\n",
    "                               linestyle=\"-\")\n",
    "    \n",
    "    # Add lines for Tb and DAV thresholds\n",
    "    for ax in [axes[0], axes[2]]:\n",
    "        ax.axhline(y=Tb_threshold, color='gray',\n",
    "                   linestyle=\":\", \n",
    "                   label=\"$Tb$ = %d $K$\" % Tb_threshold)\n",
    "        \n",
    "    for ax in [axes[1], axes[3]]:\n",
    "        ax.axhline(y=DAV_threshold, color='gray',\n",
    "                   linestyle=\":\", \n",
    "                   label=\"$DAV$ = %d $K$\" % DAV_threshold)\n",
    "        \n",
    "    axes[4].axhline(y=0., color='gray',\n",
    "                   linestyle=\":\", \n",
    "                   label=\"$T$ = %d $K$\" % 0.)\n",
    "\n",
    "    if do_MOD_lines:\n",
    "        \n",
    "        # Add lines for SIR MODs to discharge plot\n",
    "        for ax in [axes[5]]:\n",
    "            for i, mod in enumerate(station_SIR_MOD):\n",
    "                if i == 0:\n",
    "                    ax.axvline(x=mod, color='orangered',\n",
    "                               linestyle=\"-\",\n",
    "                               label=\"SIR Melt Onset\")\n",
    "                else:\n",
    "                    ax.axvline(x=mod, color='orangered',\n",
    "                               linestyle=\"-\")\n",
    "    \n",
    "    for ax in axes:\n",
    "        ax.legend(framealpha=0.5, loc='upper right')\n",
    "        \n",
    "    plt.tight_layout()\n",
    "    outfile = '/projects/brodzik/pmesdr_melt_onset/data/%s_%s_%s_%d-%d_%s_rSIR_vs_GRD_TB_tseries.png' % (\n",
    "        station['name'], platform, sensor, Years[0], Years[-1], channel)\n",
    "    fig.savefig(outfile, dpi=300)\n",
    "    print(\"Saved plot to %s\" % outfile)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
