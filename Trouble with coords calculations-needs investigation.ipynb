{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# This notebook is investigating TB and MOD data for the Hunza met station locations\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load in all the modules needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "%pylab notebook\n",
    "import cartopy.crs as ccrs\n",
    "import cartopy.io.shapereader as shpreader\n",
    "import shapely.geometry as sgeom\n",
    "import matplotlib.pyplot as plt\n",
    "from netCDF4 import Dataset, num2date\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import rasterio\n",
    "from cetbtools.ease2conv import Ease2Transform\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/projects/brodzik/ipynb_melt_onset/scripts\n",
      "CETB_algorithms.py  CETB_analysis.py~       \u001b[0m\u001b[01;34m__pycache__\u001b[0m/\r\n",
      "CETB_analysis.py    CETB_read_functions.py\r\n"
     ]
    }
   ],
   "source": [
    "# navigate to where scripts are saved\n",
    "%cd /projects/brodzik/ipynb_melt_onset/scripts/\n",
    "%ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the custom functions\n",
    "from CETB_read_functions import read_Tb\n",
    "from CETB_read_functions import coords\n",
    "from CETB_read_functions import calc_DAV\n",
    "from CETB_read_functions import find_UIB_cube_offset\n",
    "from CETB_read_functions import grid_locations_of_UIB\n",
    "from CETB_algorithms import DAV_MOD\n",
    "from CETB_analysis import MOD_array\n",
    "from CETB_analysis import MOD_array_year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set pixel lookups by met station\n",
    "# ref: /Users/brodzik/Desktop/GIS_data/Pakistan/Hunza/wapda_met_stations_CETBlocs.v4.xlsx\n",
    "Khunjerab = {\"name\": \"Khunjerab\",\n",
    "             \"lat\": 36.8411,\n",
    "             \"lon\": 75.4192,\n",
    "             \"row3km\": 220,\n",
    "             \"col3km\": 41,\n",
    "             \"row25km\": 27,\n",
    "             \"col25km\": 5\n",
    "           }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'name': 'Khunjerab',\n",
       " 'lat': 36.8411,\n",
       " 'lon': 75.4192,\n",
       " 'row3km': 220,\n",
       " 'col3km': 41,\n",
       " 'row25km': 27,\n",
       " 'col25km': 5}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "station = Khunjerab\n",
    "station"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read TB data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Specify region, satellite, sensor, channel, and image reconstruction algorithm of interest in file name\n",
    "# this notebook will read in 2 CETB datasets so that channels/algorithms/sensors can be compared\n",
    "region='UIB'  #make this the same syntax as cubefilenames and sub-directory\n",
    "platform='AQUA'   #'AQUA' for AMSRE, 'F13','F14','F15'... for SSMI\n",
    "sensor='AMSRE'  #'AMSRE', 'SSMI', etc.\n",
    "channel='36V'  #'36V','36H', '18V','18H', etc. '19V','19H' and '37V','37H' for SSMI)\n",
    "version='v1.3'\n",
    "proj='N'\n",
    "\n",
    "if sensor=='SSMI':\n",
    "    provider='CSU' \n",
    "elif sensor=='AMSRE':\n",
    "    provider='RSS'\n",
    "\n",
    "cubeDir = '/work/PMESDR/CETB_v1.3/%s_%s/%s/cubes_%s/' % (platform, sensor, proj, region)    \n",
    "\n",
    "# prefix filepath\n",
    "prefix_GRD = 'CETB.cubefile.%s.%s_%s-%s-GRD-%s-%s' % (region, platform, sensor, channel, provider, version)\n",
    "prefix_SIR = 'CETB.cubefile.%s.%s_%s-%s-SIR-%s-%s' % (region, platform, sensor, channel, provider, version)\n",
    "\n",
    "# years for each sensor\n",
    "# F13, May 95 - Nov 09\n",
    "if platform=='F13':\n",
    "    # F13, May 95 - Nov 09\n",
    "    Years = [2002,2003,2004,2005,2006,2007,2008,2009]\n",
    "elif platform=='F14':\n",
    "    # F14, May 97 - Aug 08\n",
    "    Years=[2002,2003,2004,2005,2006,2007,2008]\n",
    "elif platform=='F15':\n",
    "    # F15, Feb 00 - Jun 17\n",
    "    Years=[2002,2003,2004,2005,2006,2007,2008,2009,2010,2011]\n",
    "elif platform=='AQUA':\n",
    "    # AQUA AMSR-E: Jun 02 - Oct 11\n",
    "    Years=[2003,2004,2005,2006,2007,2008,2009,2010,2011]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "E2N UL corner lon=-135.0000, lat=-84.6340\n"
     ]
    }
   ],
   "source": [
    "# Set up cartopy CRSs for E2N and \n",
    "# for UIB cubes, I want to rotate 90 degrees clockwise\n",
    "geod = ccrs.Geodetic()\n",
    "e2n = ccrs.LambertAzimuthalEqualArea(central_latitude=90.0)\n",
    "e2nRotate = ccrs.LambertAzimuthalEqualArea(central_latitude=90.0, central_longitude=90.0)\n",
    "\n",
    "# Sanity check\n",
    "lon, lat = geod.transform_point(\n",
    "    x = -9000000.,\n",
    "    y = 9000000.,\n",
    "    src_crs=e2n)\n",
    "print(\"E2N UL corner lon=%.4f, lat=%.4f\" % (lon, lat))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read the UIB shapefile to get the bounds of the cube area\n",
    "\n",
    "Read the basin outline shapefiles\n",
    "Use shapely to read the .shp files. This works for lonlat shapefiles, it doesn't seem to work for projected ones, there must be an option that I'm just missing.\n",
    "\n",
    "Use the cartopy CRS to project the shapefile to E2N"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "hunzaBasinfile = '/work/charis/ti_model/basins/basin_outlines/IN_Hunza_at_DainyorBridge.shp'\n",
    "hunzaReader = shpreader.Reader(hunzaBasinfile)\n",
    "hunzaRecord = next(hunzaReader.records())\n",
    "#hunzaRecord, hunzaRecord.attributes, hunzaRecord.bounds, hunzaRecord.geometry"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rotate/project the basin outline shapefiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "e2nRotateHunzaBasin = e2nRotate.project_geometry(hunzaRecord.geometry)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(74.02507731119763, 35.92307128906174, 75.77779744466116, 37.09783732096277)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bounds = hunzaRecord.bounds\n",
    "Site = \"Hunza\"\n",
    "#bounds = UIBRecord.bounds\n",
    "#Site = \"UIB\"\n",
    "bounds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'name': 'Khunjerab',\n",
       " 'lat': 36.8411,\n",
       " 'lon': 75.4192,\n",
       " 'row3km': 220,\n",
       " 'col3km': 41,\n",
       " 'row25km': 27,\n",
       " 'col25km': 5}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "station"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<code>\n",
    "forward_grid:\n",
    "enter lat lon: 36.8411 75.4192\n",
    "col,row = 580.679566 417.033822    status = 1\n",
    "lat,lon = 36.841100 75.419200    status = 1\n",
    "enter lat lon: \n",
    "    </code>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(26, 27, 6, 7)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get the GRD pixel IDs for station location\n",
    "rows_cols_GRD=coords(cubeDir, prefix_GRD, station['lat'], station['lat'], station['lon'], station['lon'])\n",
    "rows_cols_GRD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(210, 211, 54, 55)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get the GRD pixel IDs for station location\n",
    "rows_cols_env=coords(cubeDir, prefix_SIR, station['lat'], station['lat'], station['lon'], station['lon'])\n",
    "rows_cols_env"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "27*8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No subset specified, fetching complete cube...\n",
      "No subset specified, fetching complete cube...\n"
     ]
    }
   ],
   "source": [
    "# load in SIR TB data\n",
    "data_SIR=read_Tb(cubeDir, prefix_SIR, Years)\n",
    "CETB_SIR=data_SIR['TB']   # 3-D Tb time-series array of TB\n",
    "cal_date=data_SIR['cal_date']    # 1-D array of dates, these will get passed to later functions\n",
    "cal_year=data_SIR['cal_year']    # 1-D array of years\n",
    "cal_month=data_SIR['cal_month']   # 1-D array of months\n",
    "\n",
    "# load GRD Tb data\n",
    "data_GRD=read_Tb(cubeDir, prefix_GRD, Years)\n",
    "CETB_GRD=data_GRD['TB']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare Mitch's coords answer to the one I get with mapx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((210, 211, 54, 55), 36.51889472705087, 75.81636978500872)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#mitch_lat = data_GRD['latitude'][rows_cols_GRD[0]][rows_cols_GRD[2]]\n",
    "#mitch_lon = data_GRD['longitude'][rows_cols_GRD[0]][rows_cols_GRD[2]]\n",
    "mitch_lat = data_SIR['latitude'][rows_cols_env[0]][rows_cols_env[2]]\n",
    "mitch_lon = data_SIR['longitude'][rows_cols_env[0]][rows_cols_env[2]]\n",
    "#rows_cols_GRD, mitch_lat, mitch_lon\n",
    "rows_cols_env, mitch_lat, mitch_lon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'name': 'Khunjerab',\n",
       "  'lat': 36.8411,\n",
       "  'lon': 75.4192,\n",
       "  'row3km': 220,\n",
       "  'col3km': 41,\n",
       "  'row25km': 27,\n",
       "  'col25km': 5},\n",
       " 36.837347378374396,\n",
       " 75.41274294152329)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#my_lat = data_GRD['latitude'][station['row25km']][station['col25km']]\n",
    "#my_lon = data_GRD['longitude'][station['row25km']][station['col25km']]\n",
    "#station, my_lat, my_lon\n",
    "my_lat = data_SIR['latitude'][station['row3km']][station['col3km']]\n",
    "my_lon = data_SIR['longitude'][station['row3km']][station['col3km']]\n",
    "station, my_lat, my_lon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(-0.0037526216256011935, -0.3222052729491267)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_lat - station['lat'], mitch_lat - station['lat']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(-0.006457058476712518, 0.3971697850087139)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_lon - station['lon'], mitch_lon - station['lon']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate DAV for the Tb data that was imported\n",
    "DAV_SIR=calc_DAV(CETB_SIR)\n",
    "DAV_GRD=calc_DAV(CETB_GRD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Given a cube's (or subset's) x, y values\n",
    "# calculate the extent of the edges \n",
    "# as 1/2 pixel larger than centers of corner pixels\n",
    "def get_extent_xy(x, y):\n",
    "    # Assumes pixels with regular spacing\n",
    "    scale_x = x[1] - x[0]\n",
    "    scale_y = y[1] - y[0]\n",
    "    print(\"scales: \", scale_x, scale_y)\n",
    "    \n",
    "    extent = [x[0] - (scale_x/2.),\n",
    "              x[-1] + (scale_x/2.),\n",
    "              y[-1] + (scale_y/2.),\n",
    "              y[0] - (scale_y/2.)]\n",
    "              \n",
    "    return extent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check extents of full cube"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_GRD['x'].shape, data_GRD['y'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_extent_xy(data_SIR['x'], data_SIR['y'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_extent_xy(data_GRD['x'], data_GRD['y'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check extents of requested subsets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_extent_xy(data_SIR['x'][rows_cols_env[2]:rows_cols_env[3]],\n",
    "              data_SIR['y'][rows_cols_env[0]:rows_cols_env[1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_extent_xy(data_GRD['x'][rows_cols_GRD[2]:rows_cols_GRD[3]],\n",
    "              data_GRD['y'][rows_cols_GRD[0]:rows_cols_GRD[1]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read DEMs at 3.125 and 25 km for displays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DEM25kmFile = '/work/charis/ti_model/SRTMGL3_version2_EASE2/EASE2_N25km.CHARIS_DEM_v2_IN.UIB_Khan_clip.mode.tif'\n",
    "with rasterio.open(DEM25kmFile) as src:\n",
    "    dem25km = np.squeeze(src.read())\n",
    "DEM3kmFile = '/work/charis/ti_model/SRTMGL3_version2_EASE2/EASE2_N3.125km.CHARIS_DEM_v2_IN.UIB_Khan_clip.mode.tif'\n",
    "with rasterio.open(DEM3kmFile) as src:\n",
    "    dem3km = np.squeeze(src.read())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## create arrays of MOD to be used for plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get array of average MODs for SIR pixels for all the years loaded\n",
    "window=10   # window for MOD algorithm, '10' would be 5 days (2 measurements per day)\n",
    "count=3    # number of Tb/DAV exceedances to trigger MOD\n",
    "DAV_threshold=40\n",
    "Tb_threshold=252"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Years"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# sir MOD array - MOD will be in day of year (DOY)\n",
    "t = time.process_time()\n",
    "MOD_DOY_array=MOD_array(cubeDir, prefix_SIR, CETB_SIR, DAV_SIR, \n",
    "                        rows_cols_env, cal_date, Years, window, count, DAV_threshold, Tb_threshold)\n",
    "elapsed_time = time.process_time() - t\n",
    "MOD_DOY_array, elapsed_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# MOD of the GRD pixel - avg all years\n",
    "#window=10\n",
    "#count=3\n",
    "#DAV_threshold=18\n",
    "#Tb_threshold=252\n",
    "t = time.process_time()\n",
    "MOD_DOY_array_GRD=MOD_array(cubeDir, prefix_GRD, CETB_GRD, DAV_GRD, \n",
    "                            rows_cols_GRD, cal_date, Years, window, count, DAV_threshold, Tb_threshold)\n",
    "elapsed_time = time.process_time() - t\n",
    "MOD_DOY_array_GRD, elapsed_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save these arrays to numpy zip\n",
    "outfile = '/projects/brodzik/pmesdr_melt_onset/data/%s_%s_%s_%d-%d_MOD.DAV%03d.Tb%03d.npz' % (\n",
    "    Site, platform, sensor, Years[0], Years[-1], DAV_threshold, Tb_threshold)\n",
    "np.savez(outfile, \n",
    "         MOD_DOY_array=MOD_DOY_array, \n",
    "         MOD_DOY_array_GRD=MOD_DOY_array_GRD)\n",
    "print(\"Avg SIR and GRD MODs saved to %s\" % outfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For each individual year, do SIR and GRD MOD\n",
    "\n",
    "# get array of MOD for each pixel SIR - one year of interest\n",
    "#window=10\n",
    "#count=3\n",
    "#DAV_threshold=18\n",
    "#Tb_threshold=252\n",
    "\n",
    "# For each individual year, do SIR MOD\n",
    "for year in Years:\n",
    "    print(\"year = %d\" % year)\n",
    "    t = time.process_time()\n",
    "    MOD_DOY_array_year=MOD_array_year(cubeDir, prefix_SIR, CETB_SIR, DAV_SIR, \n",
    "                                      rows_cols_env, cal_date, year, \n",
    "                                      window, count, DAV_threshold, Tb_threshold)\n",
    "    elapsed_time = time.process_time() - t\n",
    "    print(\"SIR elapsed time = %f\" % elapsed_time)\n",
    "    \n",
    "    t = time.process_time()\n",
    "    MOD_DOY_array_GRD_year=MOD_array_year(cubeDir, prefix_GRD, CETB_GRD, DAV_GRD, \n",
    "                                          rows_cols_GRD, cal_date, year, \n",
    "                                          window, count, DAV_threshold, Tb_threshold)\n",
    "    elapsed_time = time.process_time() - t\n",
    "    print(\"GRD elapsed time = %f\" % elapsed_time)\n",
    "    \n",
    "    outfile = '/projects/brodzik/pmesdr_melt_onset/data/%s_%s_%s_%d_MOD.DAV%03d.Tb%03d.npz' % (\n",
    "        Site, platform, sensor, year, DAV_threshold, Tb_threshold)\n",
    "    np.savez(outfile, \n",
    "             MOD_DOY_array_year=MOD_DOY_array_year,\n",
    "             MOD_DOY_array_GRD_year=MOD_DOY_array_GRD_year)\n",
    "    print(\"MOD data saved to %s\" % outfile)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data produced earlier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This will need to be changed to read the particular year of interest\n",
    "# Load data saved on previous runs\n",
    "outfile = '/projects/brodzik/pmesdr_melt_onset/data/%s_%s_%s_%d-%d_MOD.DAV%03d.Tb%03d.npz' % (\n",
    "    Site, platform, sensor, Years[0], Years[-1], DAV_threshold, Tb_threshold)\n",
    "npzfile = np.load(outfile)\n",
    "print(\"Loading avg data from %s\" % outfile)\n",
    "#npzfile.files\n",
    "# should return 2 avg MOD variable names as a dict\n",
    "MOD_DOY_array = npzfile['MOD_DOY_array']\n",
    "MOD_DOY_array_GRD = npzfile['MOD_DOY_array_GRD']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the year to read\n",
    "year = 2011\n",
    "outfile = '/projects/brodzik/pmesdr_melt_onset/data/%s_%s_%s_%d_MOD.DAV%03d.Tb%03d.npz' % (\n",
    "        Site, platform, sensor, year, DAV_threshold, Tb_threshold)\n",
    "npzfile = np.load(outfile)\n",
    "print(\"Loading year=%d data from %s\" % (year, outfile))\n",
    "MOD_DOY_array_year = npzfile['MOD_DOY_array_year']\n",
    "MOD_DOY_array_GRD_year = npzfile['MOD_DOY_array_GRD_year']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convert the MOD information back to an image for display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MOD_DOY = MOD_DOY_array.reshape((rows_cols_env[1] - rows_cols_env[0],\n",
    "                                 rows_cols_env[3] - rows_cols_env[2]))\n",
    "MOD_DOY_year = MOD_DOY_array_year.reshape((rows_cols_env[1] - rows_cols_env[0],\n",
    "                                           rows_cols_env[3] - rows_cols_env[2]))\n",
    "                                         \n",
    "MOD_DOY_GRD = MOD_DOY_array_GRD.reshape((rows_cols_GRD[1] - rows_cols_GRD[0],\n",
    "                                         rows_cols_GRD[3] - rows_cols_GRD[2]))\n",
    "MOD_DOY_GRD_year = MOD_DOY_array_GRD_year.reshape((rows_cols_GRD[1] - rows_cols_GRD[0],\n",
    "                                                   rows_cols_GRD[3] - rows_cols_GRD[2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(14,6))\n",
    "\n",
    "# Figure out the extent to display and rotate the extent by 90 degrees\n",
    "# This extent is for the current selected subset of the UIB cube\n",
    "cube_extent=get_extent_xy(data_GRD['x'][rows_cols_GRD[2]:rows_cols_GRD[3]], \n",
    "                          data_GRD['y'][rows_cols_GRD[0]:rows_cols_GRD[1]])\n",
    "cube_extentRotate=[cube_extent[2], cube_extent[3], -1.*cube_extent[1], -1. * cube_extent[0]]\n",
    "\n",
    "# Placeholders for the various elements of each subplot\n",
    "axes = []\n",
    "images = []\n",
    "\n",
    "numrows = 2\n",
    "numcols = 3\n",
    "numplots = numrows * numcols\n",
    "\n",
    "labels = [\"SRTMGL3 DEM (3.125 km)\",\n",
    "          \"%s %s SIR Avg MOD (%4d-%4d)\" % (platform, sensor, Years[0], Years[-1]),\n",
    "          \"%s %s SIR MOD (%s)\" % (platform, sensor, year),\n",
    "          \"SRTMGL3 DEM (25 km)\",\n",
    "          \"%s %s GRD Avg MOD (%4d-%4d)\" % (platform, sensor, Years[0], Years[-1]),\n",
    "          \"%s %s GRD MOD (%s)\" % (platform, sensor, year)]\n",
    "color_labels = [\"Elevation (m)\",\n",
    "                \"DOY\",\n",
    "                \"DOY\",\n",
    "                \"Elevation (m)\",\n",
    "                \"DOY\",\n",
    "                \"DOY\"]\n",
    "\n",
    "# Set the projection and extent for each subplot\n",
    "for i in np.arange(numplots):\n",
    "    axes.append(fig.add_subplot(numrows, numcols, i+1, projection=e2nRotate))\n",
    "    axes[i].set_extent(cube_extentRotate, crs=e2nRotate)\n",
    "\n",
    "images.append(axes[0].imshow(np.rot90(\n",
    "    dem3km[rows_cols_env[0]:rows_cols_env[1], rows_cols_env[2]:rows_cols_env[3]], -1),\n",
    "                             extent=cube_extentRotate, \n",
    "                             transform=e2nRotate,\n",
    "                             origin='upper', cmap='Greys_r', \n",
    "                             interpolation='None', vmin=np.min(150), vmax=np.max(8000), label=labels[0]))\n",
    "\n",
    "images.append(axes[1].imshow(np.rot90(MOD_DOY, -1), \n",
    "                             extent=cube_extentRotate, \n",
    "                             transform=e2nRotate,\n",
    "                             origin='upper', cmap='RdBu', \n",
    "                             interpolation='None', vmin=np.min(75), vmax=np.max(170), label=labels[1]))\n",
    "\n",
    "images.append(axes[2].imshow(np.rot90(MOD_DOY_year, -1), \n",
    "              extent=cube_extentRotate, \n",
    "              transform=e2nRotate,\n",
    "              origin='upper', cmap='RdBu', \n",
    "              interpolation='None', vmin=np.min(75), vmax=np.max(170), label=labels[2]))\n",
    "\n",
    "images.append(axes[3].imshow(np.rot90(\n",
    "    dem25km[rows_cols_GRD[0]:rows_cols_GRD[1], rows_cols_GRD[2]:rows_cols_GRD[3]], -1),\n",
    "                             extent=cube_extentRotate, \n",
    "                             transform=e2nRotate,\n",
    "                             origin='upper', cmap='Greys_r', \n",
    "                             interpolation='None', vmin=np.min(150), vmax=np.max(8000), label=labels[3]))\n",
    "\n",
    "images.append(axes[4].imshow(np.rot90(MOD_DOY_GRD, -1), \n",
    "                           extent=cube_extentRotate, \n",
    "                           transform=e2nRotate,\n",
    "                           origin='upper', cmap='RdBu', \n",
    "                           interpolation='None', vmin=np.min(75), vmax=np.max(170), label=labels[4]))\n",
    "\n",
    "images.append(axes[5].imshow(np.rot90(MOD_DOY_GRD_year, -1), \n",
    "              extent=cube_extentRotate, \n",
    "              transform=e2nRotate,\n",
    "              origin='upper', cmap='RdBu', \n",
    "              interpolation='None', vmin=np.min(75), vmax=np.max(170), label=labels[5]))\n",
    "\n",
    "# Do common display stuff for each subplot\n",
    "for i in np.arange(numplots):\n",
    "    axes[i].axis('off')\n",
    "    axes[i].gridlines(color='gray', linestyle='--')\n",
    "    axes[i].coastlines()\n",
    "    axes[i].add_geometries([e2nRotateUIBBasin], \n",
    "                      e2nRotate,\n",
    "                      edgecolors='black', facecolor='none', lw=2)\n",
    "    axes[i].add_geometries([e2nRotateHunzaBasin], e2nRotate,\n",
    "                      edgecolors='red', facecolor='none', lw=2)\n",
    "    #For separate colorbars:\n",
    "    cbar = fig.colorbar(images[i], ax=axes[i])\n",
    "    cbar.ax.set_ylabel(color_labels[i])\n",
    "    axes[i].set_title(labels[i])\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "pngfile = \"/projects/brodzik/pmesdr_melt_onset/data/%s_%s_%s_%d-%d_w%d.MOD.DAV%03d.Tb%03d.png\" % (\n",
    "    Site, platform, sensor, Years[0], Years[-1], year, DAV_threshold, Tb_threshold)\n",
    "fig.savefig(pngfile, dpi=300)\n",
    "print(\"Saved plot to %s\" % pngfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
